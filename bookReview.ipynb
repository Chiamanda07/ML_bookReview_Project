{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:  \n",
    "1. I chose bookReviewsData.csv  \n",
    "2. I will be predicting whether a review is positive or not. The label is `Positive Review`.  \n",
    "3. This would be a supervised binary classification problem\n",
    "4. My feature would be the `Review` column.  \n",
    "5. This model can help a company determine how well their product is doing in the market. Whether a lot of people like it or it should be discontinued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review             object\n",
       "Positive Review      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review             False\n",
       "Positive Review    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if the classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    993\n",
       "True     980\n",
       "Name: Positive Review, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Positive Review\"]. value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "This was perhaps the best of Johannes Steinhoff's books, since it does not  deal with his own stellar yet tragic WW II and post war career. The  insights of the average person living in Germany are of great importance to  both social and military historians alike. Steinhoff offered this  collective testament as a warning to all of us regarding war and the rise  of a dictator. As Johannes said in an interview, &quot;It is always the  civilians who suffer the most, yet are remembered the least.&quot\n",
      "\n",
      "\n",
      "Positive review : True\n",
      "----------------------------------------\n",
      "\n",
      "Review 2:\n",
      "This very fascinating book is a story written in the form of numerous letters and personal diary entries made by the principle character of the book.  It chronicals the life of a young Scottish woman forced to live first in China then Japan.  Well written and historically accurate, it's obvious the author is intimately familiar with the the culture, customs, history and life style of Japan.  This makes the book that much more interesting and fascinating for those who enjoy realism and demand accuracy in a story.  For all who've ever lived in Japan, it's a believable tale that literally makes you feel you've stepped back in a time machine to witness the birth of modern Japan.  For those who haven't lived in Japan, believe that the author has done his homework and is not simply just creating a fictional setting in his mind.  Because of this, he's able to focus on his character versus scene/setting development and thus creates a living breathing person in your mind.  The timespan covers over 40 years as the story weaves through her trials and tribulations, and shows how her fortitude and strength serve her through tumultuous events in her life.  A gripping tale that draws on your emotions and has you constantly rooting for her.  When the last page is read it leaves you wishing the story would continue, but even good books must end.  Be prepared to sit a spell.  Once you start reading you'll find it hard to put down\n",
      "\n",
      "\n",
      "Positive review : True\n",
      "----------------------------------------\n",
      "\n",
      "Review 3:\n",
      "The four tales in this collection are beautifully composed; they are art, not just stories.  Each story is deep in its unique complexities.  Each one has plots and subplots and paints an impeccable image of the story upon the reader's mind.  And when I look back upon the book as a whole, upon the adventurous stories, the excitement and emotion that the author presents so exquisitely, I can't help but be extremely impressed.\n",
      "\n",
      "\n",
      "Positive review : True\n",
      "----------------------------------------\n",
      "\n",
      "Review 4:\n",
      "The book contained more profanity than I expected to read in a book by Rita Rudner.  I had expected more humor from a comedienne.  Too bad, because I really like her humor\n",
      "\n",
      "\n",
      "Positive review : False\n",
      "----------------------------------------\n",
      "\n",
      "Review 5:\n",
      "We have now entered a second time of deep concern for the science, math, and technological education for everyone. The first one occurred after the Sputnik fiasco, when the Russians beat us in the race to reach space. The  concern now has risen due to what science groups such as the American  Association for the Advancement of Science, and educators saw in comparison  of assessments made of students in the U.S. and those in other developed  countries, such as Japan. The answer to this concern was for the AAAS along  with other groups to put out a guideline as to what constitutes scientific  literacy, and what the public in the U.S. should at least know to be  scientifically literate. As usual, though the AAAS addressed the fact that  certain groups in the U.S. were not being 'included' in the pursuit of  science literacy, such as women and racial minorities, in this their first  book they skipped over those of us with disabilities. Since this is a major  concern of mine and the area in which I do research, I was appalled to see  they neglected 'us' once again, especially as the AAAS has a separate  department dealing with the Disabled/Deaf.  In spite of this mistake, the  writing of this book has laid the groundwork for universities and colleges  as to what the teachers they train should know and be able to teach so that  our country can be more scientifically literate. With new information being  made available through newspapers and the Internet on a daily basis, it is  absolutely imperative that all adults regardless of race, gender, or  ability be able to glean the information they need from this outpouring of  information to make decisions requiring informed consent in health care,  decisions on employment (since health care is one of the top employers in  the U.S. today), and to teach their children. This book was the beginning,  but it isn't the end. More books have further elucidated what is required  for science literacy from both the AAAS and other science groups. This is  the place to start if you are an educator of any kind who wants their  students to become scientifically literate. Karen Sadler, Science  Education, University of Pittsburgh, klsst23@pitt.ed\n",
      "\n",
      "\n",
      "Positive review : True\n",
      "----------------------------------------\n",
      "\n",
      "Review 6:\n",
      "I don't know why it won the National Book Award.  This book is very slow, &amp; very boring.  Where is the action?  I forced myself to finish it\n",
      "\n",
      "\n",
      "Positive review : False\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, review in enumerate(df[\"Review\"].loc[:5]):\n",
    "    preview = df[\"Positive Review\"][i]\n",
    "    print(f\"Review {i+1}:\\n{review}\\n\")\n",
    "    print(f\"Positive review : {preview}\\n{'-'*40}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.12.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would have removed stop words using genism; however, looking at its documentation, some of these words appear to be key indicators of whether a review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I'll separate the dataset to its feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Review\"]\n",
    "y = df[\"Positive Review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a feature column: \"Review\"  \n",
    "I'm going to  try and perform word embedding first, as context is key to the problem I'm addressing.  \n",
    "I'm also going to use n-grams of 2 or more, since this is a sentiment analysis, and words like \"not\" could play a vital role.  \n",
    "As for my model, I'm going to be using a traditional neural network.  \n",
    "During the training period, I'm going to use an SGD optimizer, Binary Cross Entropy as my loss function, an accuracy metric.  \n",
    "Depending on how my model performs, I'm going to be changing the number of hidden layers (starting from 3 layers), epochs, dropout layers (for regularization), and min_df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:25:21.234787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-07-30 03:25:21.234825: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change of Plans**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially tried using word embedding, but I got really low results. I believe its because before I passed it into the neural network, I had to calculate the average of the vectors and use that. This could have made the word embeddings lose their meaning.  \n",
    "So I'm going to use TFIDF vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing TFIDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X,y, test_size = 0.25, random_state = 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a TfidfVectorizer object \n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 2, ngram_range=(1,4))\n",
    "\n",
    "\n",
    "# 2. Fit the vectorizer to X_train\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "# 3. Using the fitted vectorizer, transform the training data \n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "\n",
    "\n",
    "# 4. Using the fitted vectorizer, transform the test data \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77609\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 77609)             0         \n",
      "_________________________________________________________________\n",
      "hl_1 (Dense)                 (None, 64)                4967040   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "hl_2 (Dense)                 (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "hl_3 (Dense)                 (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,969,665\n",
      "Trainable params: 4,969,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:25:24.283814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-07-30 03:25:24.283845: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-07-30 03:25:24.283864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (i-0bc3e2374dea6c8da): /proc/driver/nvidia/version does not exist\n",
      "2025-07-30 03:25:24.284070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Model object\n",
    "nn_model = keras.Sequential()\n",
    "\n",
    "# Input layer \n",
    "input_layer = keras.layers.InputLayer(input_shape = vocabulary_size, name = \"input\")\n",
    "nn_model.add(input_layer)\n",
    "nn_model.add(keras.layers.Dropout(.25))\n",
    "# First hidden layer \n",
    "hidden_layer_1 = keras.layers.Dense(units = 64, activation = \"relu\", name = \"hl_1\")\n",
    "nn_model.add(hidden_layer_1)\n",
    "nn_model.add(keras.layers.Dropout(.25))\n",
    "# Second hidden layer \n",
    "hidden_layer_2 = keras.layers.Dense(units = 32, activation = \"relu\", name = \"hl_2\")\n",
    "nn_model.add(hidden_layer_2)\n",
    "nn_model.add(keras.layers.Dropout(.25))\n",
    "\n",
    "# Third hidden layer\n",
    "hidden_layer_3 = keras.layers.Dense(units = 16, activation = \"relu\", name = \"hl_3\")\n",
    "nn_model.add(hidden_layer_3)\n",
    "nn_model.add(keras.layers.Dropout(.4))\n",
    "\n",
    "\n",
    "#Output layer \n",
    "output_layer = keras.layers.Dense(units = 1, activation = \"sigmoid\", name = \"output\")\n",
    "nn_model.add(output_layer)\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = keras.optimizers.SGD(learning_rate = 0.1)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "nn_model.compile(optimizer = sgd_optimizer, loss = loss_fn, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgBarLoggerNEpochs(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, num_epochs: int, every_n: int = 50):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.every_n = every_n\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.every_n == 0:\n",
    "            s = 'Epoch [{}/ {}]'.format(epoch + 1, self.num_epochs)\n",
    "            logs_s = ['{}: {:.4f}'.format(k.capitalize(), v)\n",
    "                      for k, v in logs.items()]\n",
    "            s_list = [s] + logs_s\n",
    "            print(', '.join(s_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:25:25.376032: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2025-07-30 03:25:25.376394: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2649995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/ 95], Loss: 0.6928, Accuracy: 0.5089, Val_loss: 0.6925, Val_accuracy: 0.6453\n",
      "Epoch [10/ 95], Loss: 0.6888, Accuracy: 0.5495, Val_loss: 0.6898, Val_accuracy: 0.4966\n",
      "Epoch [15/ 95], Loss: 0.6674, Accuracy: 0.6365, Val_loss: 0.6765, Val_accuracy: 0.5439\n",
      "Epoch [20/ 95], Loss: 0.6010, Accuracy: 0.6974, Val_loss: 0.7043, Val_accuracy: 0.5034\n",
      "Epoch [25/ 95], Loss: 0.5237, Accuracy: 0.7447, Val_loss: 0.7241, Val_accuracy: 0.5236\n",
      "Epoch [30/ 95], Loss: 0.3609, Accuracy: 0.8740, Val_loss: 0.5110, Val_accuracy: 0.7399\n",
      "Epoch [35/ 95], Loss: 0.2615, Accuracy: 0.9121, Val_loss: 0.8990, Val_accuracy: 0.6149\n",
      "Epoch [40/ 95], Loss: 0.4873, Accuracy: 0.8462, Val_loss: 0.7964, Val_accuracy: 0.6149\n",
      "Epoch [45/ 95], Loss: 0.2102, Accuracy: 0.9434, Val_loss: 0.3798, Val_accuracy: 0.8412\n",
      "Epoch [50/ 95], Loss: 0.0411, Accuracy: 0.9975, Val_loss: 0.4239, Val_accuracy: 0.8378\n",
      "Epoch [55/ 95], Loss: 0.3302, Accuracy: 0.8893, Val_loss: 2.0104, Val_accuracy: 0.4966\n",
      "Epoch [60/ 95], Loss: 0.2943, Accuracy: 0.9036, Val_loss: 0.5148, Val_accuracy: 0.8041\n",
      "Epoch [65/ 95], Loss: 0.0730, Accuracy: 0.9949, Val_loss: 0.3796, Val_accuracy: 0.8446\n",
      "Epoch [70/ 95], Loss: 0.0491, Accuracy: 0.9915, Val_loss: 0.4569, Val_accuracy: 0.8378\n",
      "Epoch [75/ 95], Loss: 0.0474, Accuracy: 0.9932, Val_loss: 0.4078, Val_accuracy: 0.8547\n",
      "Epoch [80/ 95], Loss: 0.0255, Accuracy: 0.9975, Val_loss: 0.4689, Val_accuracy: 0.8547\n",
      "Epoch [85/ 95], Loss: 0.3331, Accuracy: 0.9146, Val_loss: 0.6033, Val_accuracy: 0.7736\n",
      "Epoch [90/ 95], Loss: 0.0207, Accuracy: 0.9992, Val_loss: 0.4899, Val_accuracy: 0.8581\n",
      "Epoch [95/ 95], Loss: 0.0117, Accuracy: 0.9983, Val_loss: 0.9159, Val_accuracy: 0.7669\n",
      "Elapsed time: 44.45s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()  # start time\n",
    "\n",
    "num_epochs = 95  # epochs\n",
    "\n",
    "history = nn_model.fit(\n",
    "    X_train_tfidf.toarray(),\n",
    "    y_train,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[ProgBarLoggerNEpochs(num_epochs, every_n=5)]\n",
    ")\n",
    "\n",
    "t1 = time.time()  # stop time\n",
    "\n",
    "print('Elapsed time: %.2fs' % (t1 - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8684 - accuracy: 0.7854\n",
      "Loss:  0.8684330582618713 Accuracy:  0.7854251265525818\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = nn_model.evaluate(X_test_tfidf.toarray(), y_test)\n",
    "\n",
    "print('Loss: ', str(loss) , 'Accuracy: ', str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 20 examples:\n",
      "The probability value is 0.9971, and the corresponding label in y_test is True\n",
      "The probability value is 0.9999, and the corresponding label in y_test is True\n",
      "The probability value is 0.9962, and the corresponding label in y_test is True\n",
      "The probability value is 0.9933, and the corresponding label in y_test is False\n",
      "The probability value is 0.9990, and the corresponding label in y_test is True\n",
      "The probability value is 0.9993, and the corresponding label in y_test is True\n",
      "The probability value is 0.9997, and the corresponding label in y_test is True\n",
      "The probability value is 0.9981, and the corresponding label in y_test is True\n",
      "The probability value is 0.9993, and the corresponding label in y_test is True\n",
      "The probability value is 0.9907, and the corresponding label in y_test is False\n",
      "The probability value is 0.9952, and the corresponding label in y_test is True\n",
      "The probability value is 0.9803, and the corresponding label in y_test is False\n",
      "The probability value is 0.9992, and the corresponding label in y_test is True\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "probability_predictions = nn_model.predict(X_test_tfidf.toarray())\n",
    "\n",
    "print(\"Predictions for the first 20 examples:\")\n",
    "for i, prob in enumerate(probability_predictions[:20]):\n",
    "    prob_val = prob[0]\n",
    "    if prob_val > 0.5:\n",
    "        print(f\"The probability value is {prob_val:.4f}, and the corresponding label in y_test is {y_test.to_numpy()[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to check how well it performs on some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #2:\n",
      "\n",
      "Good book on deal structure, but if you want a valuation number, check out &quot;Unlocking the Value of Your Business&quot;\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review #1:\\n')\n",
    "\n",
    "print(X_test.to_numpy()[24])\n",
    "\n",
    "goodReview = True if probability_predictions[24] >= .5 else False\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(goodReview)) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #2:\n",
      "\n",
      "Good book on deal structure, but if you want a valuation number, check out &quot;Unlocking the Value of Your Business&quot;\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review #2:\\n')\n",
    "\n",
    "print(X_test.to_numpy()[24])\n",
    "\n",
    "goodReview = True if probability_predictions[36] >= .5 else False\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(goodReview)) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[36]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #2:\n",
      "\n",
      "Good book on deal structure, but if you want a valuation number, check out &quot;Unlocking the Value of Your Business&quot;\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review #3:\\n')\n",
    "\n",
    "print(X_test.to_numpy()[24])\n",
    "\n",
    "goodReview = True if probability_predictions[492] >= .5 else False\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(goodReview)) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[492]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how much I change the drop out layers, change the epochs, or change the number of hidden layers and units, the accurcay doesn't really change from 0.7 and the loss is still much. As a result I'm going to try training a logistic regression model, as I think the dataset is small for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lrmodel= LogisticRegression()\n",
    "\n",
    "lrmodel.fit(X_train_tfidf.toarray(),y_train)\n",
    "lrprobability_predictions = lrmodel.predict_proba(X_test_tfidf.toarray())\n",
    "class_label_predictions = lrmodel.predict(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.5487183796120372\n",
      "Accuracy: 0.8137651821862348\n"
     ]
    }
   ],
   "source": [
    "#compute log loss\n",
    "l_loss = log_loss (y_test, lrprobability_predictions)\n",
    "print(f\"Log loss: {l_loss}\")\n",
    "#compute accuracy\n",
    "lracc_score = accuracy_score(y_test,class_label_predictions)\n",
    "print(f\"Accuracy: {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x72479c6d7550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,class_label_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try changing thresholds to get better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted_Probability  Predicted_Label  Actual_Label\n",
      "0               0.515439                1          True\n",
      "1               0.409019                0         False\n",
      "2               0.699246                1          True\n",
      "3               0.531948                1          True\n",
      "4               0.426856                0         False\n",
      "5               0.598959                1          True\n",
      "6               0.339826                0         False\n",
      "7               0.402986                0         False\n",
      "8               0.564441                1          True\n",
      "9               0.335148                0         False\n",
      "Accuracy: 0.8137651821862348\n",
      "   Predicted_Probability  Predicted_Label  Actual_Label\n",
      "0               0.515439                0          True\n",
      "1               0.409019                0         False\n",
      "2               0.699246                1          True\n",
      "3               0.531948                0          True\n",
      "4               0.426856                0         False\n",
      "5               0.598959                1          True\n",
      "6               0.339826                0         False\n",
      "7               0.402986                0         False\n",
      "8               0.564441                1          True\n",
      "9               0.335148                0         False\n",
      "Accuracy: 0.7591093117408907\n",
      "   Predicted_Probability  Predicted_Label  Actual_Label\n",
      "0               0.515439                0          True\n",
      "1               0.409019                0         False\n",
      "2               0.699246                0          True\n",
      "3               0.531948                0          True\n",
      "4               0.426856                0         False\n",
      "5               0.598959                0          True\n",
      "6               0.339826                0         False\n",
      "7               0.402986                0         False\n",
      "8               0.564441                0          True\n",
      "9               0.335148                0         False\n",
      "Accuracy: 0.5425101214574899\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_proba = lrmodel.predict_proba(X_test_tfidf.toarray())[:, 1]  # probabilities for class 1\n",
    "\n",
    "# Custom threshold\n",
    "threshold = [0.5, 0.55 ,0.7]  \n",
    "for t in threshold:\n",
    "    y_pred_custom = (y_proba >= t).astype(int)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted_Probability': y_proba,\n",
    "        'Predicted_Label':y_pred_custom ,\n",
    "        'Actual_Label': y_test.reset_index(drop=True)  # make sure index matches\n",
    "    })\n",
    "    print(results_df.head(10))\n",
    "    acc_score = accuracy_score(y_test,y_pred_custom)\n",
    "    print(f\"Accuracy: {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs much better than the neural network as thought. Similarly, it makes sense that 0.5 as the threshold gives the best output as it's a simple true or false label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
